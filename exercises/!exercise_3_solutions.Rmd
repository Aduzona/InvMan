---
title: "Solutions Exercise 3 - Forecasting"
author: "Thomas Kirschstein"
subtitle: Inventory Management
output:
  pdf_document: default
  html_document:
    df_print: paged
    toc: yes
    toc_float: true
    number_sections: false
---


```{r, setup, echo=F, include=T, message=FALSE, error=FALSE, warning=F}
library(DT)
library(kableExtra)
library(knitr)
library(tidyverse)
library(forecast)
library(expsmooth)
library(TTR)
#library(fpp)
#library(fpp2)

# function for calculating 1stES forecasts
first.es <- function(y, alpha = .4,  initial = c(mean(y))){
  
  n <- length(y)
  res <- matrix(NA, ncol=3, nrow=n+2)
  rownames(res) <- 0:(n+1)
  colnames(res) <- c("y","a","y.hat")
  
  res["0", c("a")] <- initial
  res[2:(n+1),"y"] <- y
  
  for(i in 2:(nrow(res)-1) ){
    res[i, "y.hat"] <- res[i-1, "a"] 
    res[i, "a"] <- alpha * res[i, "y"] + (1 - alpha) * res[i, "y.hat"]
  }
  res[n+2, "y.hat"] <- res[n+1, "a"]
  return(res)
}


# function for calculating 2ndES forecasts
sec.es <- function(y, alpha = .4, beta = .6, initial = c(mean(y), 0 )){
  
  n <- length(y)
  res <- matrix(NA, ncol=4, nrow=n+2)
  rownames(res) <- 0:(n+1)
  colnames(res) <- c("y","a","b","y.hat")
  
  res["0", c("a","b")] <- initial
  res[2:(n+1),"y"] <- y
  
  for(i in 2:(nrow(res)-1) ){
    res[i, "y.hat"] <- res[i-1, "a"] + res[i-1, "b"]
    res[i, "a"] <- alpha * res[i, "y"] + (1 - alpha) * res[i, "y.hat"]
    res[i, "b"] <- beta * (res[i, "a"]-res[i-1, "a"]) + (1 - beta) * res[i-1, "b"]
  }
  res[n+2, "y.hat"] <- res[n+1, "a"] + res[n+1, "b"]
  return(res)
}


# function for calculating 3rdES forecasts
thi.es <- function(y, alpha = .4, beta = .2, gamma=.3, periods = 4, initial = list( a = mean(y), b= 0, c= rep(0,periods) )){
  n <- length(y)
  res <- matrix(NA, ncol=5, nrow=n+1+periods)
  rownames(res) <- (-periods+1):(n+1)
  colnames(res) <- c("y","a","b","c","y.hat")
  
  res["0", c("a","b")] <- c(initial$a, initial$b)
  res[1:periods, "c"] <- initial$c
  res[(periods+1):(n+periods),"y"] <- y
  
  for(i in (periods+1):(nrow(res)-1) ){
    res[i, "y.hat"] <- res[i-1, "a"] + res[i-1, "b"]+ res[i-periods, "c"]
    res[i, "a"] <- alpha * (res[i, "y"] - res[i-periods, "c"]) + (1 - alpha) * (res[i-1, "a"] + res[i-1, "b"])
    res[i, "b"] <- beta * (res[i, "a"] - res[i-1, "a"]) + (1 - beta) * res[i-1, "b"]
    res[i, "c"] <- gamma * (res[i, "y"] - res[i-1, "a"] - res[i-1, "b"]) + (1 - gamma) *res[i-periods, "c"]
  }
  res[nrow(res), "y.hat"] <- res[nrow(res)-1, "a"] + res[nrow(res)-1, "b"] + res[nrow(res)-periods, "c"]
  return(res)
}

ts1 <- ts(c(2082,2486,2866,3380,3609,2458,1775,1785,2237, 2352, 2337, 2055, 1737, 1018, 1144, 1304, 1478, 1639, 945, 793, 679, 685, 947, 1284, 1209, 1251, 667, 357, 933, 798), deltat = 1/7)

ts2 <- ts(c(2433,3263,3135,3849	 ,2900	,3170	,3177	,3653	 ,2933	,2913	,3185	,3829	 ,3152	,2681	,3038	,3913), deltat=1/4)

ts3 <- ts(c(0,2,0,1,0,11,0,0,0,0,2,0,6,3,0,0,0,0,0,7,0,0,0,0,0,0,0,3,1,0,0,1,0,1,0,0), deltat=1/12)
```

# Forecasting for dense time series (I)

1. Apply 1st-order exponential smoothing (with $\alpha = 0.25$ and initial forecast $2,500$) and moving averages (with $n=7$).

```{r, exe-1-1, echo = F}
fc.ma <- c(NA, round(SMA(ts1, n = 7)))
fc.1es <- round(first.es(ts1, alpha=0.25, initial = 2500))
#datatable(data.frame(period = 1:31, y = c(ts1, NA),  "yhat.moving.ave" = fc.ma, "yhat.1es" = fc.1es[-1,3])  , options = list(pageLength = (length(ts1)+1)))
kable(data.frame(period = 1:31, y = c(ts1, NA),  "yhat.moving.ave" = fc.ma, "yhat.1es" = fc.1es[-1,3]))
```


2. Plot the time series. Which structural properties do you observe? Are the aforementioned forecasting models appropriate to forecast the time series?

```{r, exe-1-2, echo = F}
plot(1:30, ts1, ylab="", xlab="periods", type="b" , pch=16, xlim=c(1,31))
lines(1:31, fc.1es[-1,3], type="b", pch = 17, col="darkgrey", lty=2)
lines(1:31, fc.ma, type="b", pch = 18, col="blue", lty=3)
legend("topright", col=c("black","darkgrey","blue"), pch=16:18, lty=1:3, legend = c("y","1st ES (alpha=0.25)","mov. ave. (n=7)"), bty="n")
```

The time series shows a declining trend and seasonality pattern with a 7 period rhythm. Thus, neither 1st order exponential smoothing nor the moving average method are appropriate forecasting techniques.

3. Do you recognize the time series?

The time series shows the daily number of persons newly infected with SARS-CoV2 from April 14th till May, 13th 2020 in Germany.

```{r, exe-1-3, echo = F}
fc.corona <- ets(ts1, allow.multiplicative.trend = T, lambda="auto")
fc.corona <- c(fc.corona$fitted,as.numeric(predict(fc.corona,1)$mean) )
plot(1:30, ts1, ylab="", xlab="periods", type="b" , pch=16, xlim=c(1,31))
lines(1:31, fc.1es[-1,3], type="b", pch = 17, col="darkgrey", lty=2)
lines(1:31, fc.ma, type="b", pch = 18, col="blue", lty=3)
lines(1:31, fc.corona, type="b", pch = 19, col="red", lty=4)
legend("topright", col=c("black","darkgrey","blue","red"), pch=16:19, lty=1:4, legend = c("y","1st ES (alpha=0.25)","mov. ave. (n=7)","best ETS forecast"), bty="n")
```

# Forecasting for dense time series (II)


1. Display the time series graphically. Which typical pattern becomes obvious in the time series?

```{r, exe-2-1, echo = F}
plot(ts2, xlab="years", ylab="wine production (in 1000 hl)", type="b" , pch=16, xlim=c(1,5))
```

Stationary time series with seasonal fluctuations.

2. Calculate forecasts for the time series with 2nd-order and 3rd-order exponential smoothing (with $\alpha = \beta = \gamma = 0.3$). Display the forecasts in the same diagram. *Hint*: Initialize the forecasts with the average over all observations for $a_0$, the average slope ($b_0 = \frac{y_{16} - y_1}{16}$, and $c_{-3:0}=(-340,-200,-50,+600)$)

```{r, exe-2-2, echo = F}
fc.2es <- sec.es(ts2, alpha = 0.3 , beta = 0.3, initial = c(mean(ts2),  (ts2[16]  - ts2[1])/length(ts2))  )
fc.3es <- thi.es(ts2, alpha = 0.3 , beta = 0.3, gamma=0.3, periods = 4, initial = list( a = mean(ts2), b = (ts2[16]  - ts2[1])/length(ts2), c= c(-340,-200,-50,600) ) )
#datatable(data.frame(period = 1:(length(ts2)+1), y = c(ts2, NA),   "yhat.2es" = round(fc.2es[-c(1),4]) ,   "yhat.3es" = round(fc.3es[-c(1:4),5]) ) , options = list(pageLength = (length(ts2)+1)))
kable(data.frame(period = 1:(length(ts2)+1), y = c(ts2, NA),   "yhat.2es" = round(fc.2es[-c(1),4]) ,   "yhat.3es" = round(fc.3es[-c(1:4),5]) ))
plot(as.numeric(ts2), xlab="quarters", ylab="wine production (in 1000 hl)", type="b" , pch=16, xlim=c(1,17))
lines(fc.2es[-c(1),4], type = "b", col="darkgrey", pch = 17, lty=2)
lines(fc.3es[-c(1:4),5], type = "b", col="blue", pch = 18, lty=3)
legend("bottom" , horiz = T, col=c("black","darkgrey","blue"), lty = 1:3, pch = 16:18, legend=c("y", "2nd order ES", "3rd order ES"))
```


3. Compare the forecasts' accuracies by an appropriate measure. Which forecasting method should be chosen for the time series? 

We calculate root mean squared forecasting error (RMSFE) and the root median squared logarithmized accuracy ratio (RMSLAR).

```{r, exe-2-3, echo = F}
res.tab <- data.frame(period = 1:length(ts2), y = as.numeric(ts2),   "yhat.2es" = round(fc.2es[-c(1,nrow(fc.2es)),4]) ,   "yhat.3es" = round(fc.3es[-c(1:4,nrow(fc.3es)),5]) )
res.tab <- res.tab %>% mutate("squ.FE.2ES" = (yhat.2es - y)^2 , "squ.FE.3ES" = (yhat.3es - y)^2, "squ.LAR.2ES" = log(yhat.2es/y)^2 , "squ.LAR.3ES" = log(yhat.3es/y)^2)

#datatable(res.tab  , options = list(pageLength = nrow(res.tab) )) %>% formatRound(columns=c( "squ.LAR.2ES", "squ.LAR.3ES"), digits=3) 
kable(res.tab )
```

Based on these values the RMSFE for 2nd order ES and 3rd order ES is `r round(sqrt(mean(res.tab$squ.FE.2ES)))` and `r round(sqrt(mean(res.tab$squ.FE.3ES)) )`, respectively. Likewise, the corresponding RMSLAR values are `r round(sqrt(median(res.tab$squ.LAR.2ES)),3)` and `r round(sqrt(median(res.tab$squ.LAR.3ES)),3)`. Thus, both accuracy measures imply that (as expected) 3rd order ES delivers more accurate forecasts.

# Forecasting sporadic time series (intermittent demands)

1. Calculate forecasts for the year 2008 at the of Dec. 2007.

First, we estimate the expected non-zero demand by calculating the mean of the non-zero demand values such that $\mu=$ `r round(mean(ts3[ts3 > 0]),1)`.
Second, the distribution of interarrival times based on the time series is derived:
```{r, exe-3-1, echo = F}
# number of periods
per.vec <- 1:length(ts3)
# frequency table interarrival time
int.arr <- table(diff(per.vec[ts3 > 0])-1)/(sum(ts3 > 0)-1)
int.arr
```

Thus, at the end of 2007, for the first 7 months the following expected demands can be forecasted (ignoring the last two zero-demand periods in 2007):
```{r, exe-3-2, echo = F}
mu.nzd <- round(mean(ts3[ts3 > 0]),1)
fc.id <- 0:7
ex.dem <- as.numeric(int.arr[as.character(fc.id)]*mu.nzd)
ex.dem[is.na(ex.dem)] <- 0
#datatable(data.frame(month =  month.abb[1:8], forecast = ex.dem))
kable(data.frame(month =  month.abb[1:8], forecast = ex.dem))
```


If we take the last two zero-demand periods in 2007, we know that the inter-arrival time is at least 2, such that the forecasts change to:
```{r, exe-3-2a, echo = F}
int.arr.sub <- int.arr[as.numeric(names(int.arr)) >= 2 ]
int.arr.sub <- int.arr.sub/sum(int.arr.sub)

ex.dem <- as.numeric(int.arr.sub[as.character(2:7)]*mu.nzd)
ex.dem[is.na(ex.dem)] <- 0
#datatable(data.frame(month =  month.abb[1:6], forecast = ex.dem))
kable(data.frame(month =  month.abb[1:6], forecast = ex.dem))
```

2. Assume that in the first 3 months of 2008 no lubricants are sold. What are the forecasts for the next 3 months in 2008?

Here, we have to calculate the expected demand under the condition that inter-arrival time is at least 3 (again ignoring the last two zero-demand periods in 2007). The conditional inter-arrival time distribution is then

```{r, exe-3-3, echo = F}
int.arr.sub <- int.arr[as.numeric(names(int.arr)) >= 3 ]
int.arr.sub <- int.arr.sub/sum(int.arr.sub)
int.arr.sub
```

Thus, for April to August, the following expected demands can be forecasted:

```{r, exe-3-4, echo = F}
ex.dem.sub <- as.numeric(int.arr.sub[as.character(3:7)]*mu.nzd)
ex.dem.sub[is.na(ex.dem.sub)] <- 0
#datatable(data.frame(month =  month.abb[4:8], forecast = round(ex.dem.sub,2) ))
kable(data.frame(month =  month.abb[4:8], forecast = round(ex.dem.sub,2)))
```

Taking into account the zero-demand periods at the end of 2007, inter-arrival is at least 5 leading to the following estimates

```{r, exe-3-4a, echo = F}
int.arr.sub <- int.arr[as.numeric(names(int.arr)) >= 5 ]
int.arr.sub <- int.arr.sub/sum(int.arr.sub)
int.arr.sub

ex.dem.sub <- as.numeric(int.arr.sub[as.character(5:7)]*mu.nzd)
ex.dem.sub[is.na(ex.dem.sub)] <- 0
#datatable(data.frame(month =  month.abb[6:8], forecast = ex.dem.sub))
kable(data.frame(month =  month.abb[6:8], forecast = ex.dem.sub))
```

3. Another approach to forecast sporadic tiem series is proposed by Croston (see [here](https://otexts.com/fpp2/counts.html) for an brief introduction). Calculate forecasts by based on Croston's method for the first 3 month of 2008 either by hand or by using R.

Croston's forecasting method is basically a 1st order exponential smoothing technique applied to the non-zero demand time series and the inter-arrival time series. Thus, first both time series must be created and afterwards a 1st order ES is applied. Here we set the smoothing parameter to $\alpha=0.1$ and initialize the estimate with the first observations of each time series. Note that Croston calculates the interarrival time as the difference in the indices of two subsequent periods with non-zero demand. Thus, the inter-arrival times are higher by 1  compared to the inter-arrival times used above.

```{r, exe-3-5, echo = F}
int.arr.vec <- diff(per.vec[ts3 > 0])
nz.dem.vec <- tail(ts3[ts3 > 0],-1)

fc.nz.dem.vec <- first.es(nz.dem.vec,  alpha=0.1, initial = head(nz.dem.vec,1) )[,3]
fc.int.arr.vec <- first.es(int.arr.vec,  alpha=0.1, initial = head(int.arr.vec,1) )[,3]
# 
# datatable(data.frame(
# "int.arr" = c(NA,int.arr.vec, NA),
# "nz.dem" = c(NA,nz.dem.vec, NA) ,
# "fc.int.arr" = round(fc.int.arr.vec,3),
# "fc.nz.dem" = round(fc.nz.dem.vec,3),
# "fc.dem" = round(fc.nz.dem.vec/fc.int.arr.vec,3)
# ),
# rownames = as.character(0:(length(nz.dem.vec)+1) ),
# options = list(pageLength = (length(nz.dem.vec)+1) ))

kable(data.frame(
"int.arr" = c(NA,int.arr.vec, NA),
"nz.dem" = c(NA,nz.dem.vec, NA) ,
"fc.int.arr" = round(fc.int.arr.vec,3),
"fc.nz.dem" = round(fc.nz.dem.vec,3),
"fc.dem" = round(fc.nz.dem.vec/fc.int.arr.vec,3)
))


# Alternatively you may use the built-in function:
# tmp <- croston(ts3[-c(1:2)])
# tmp$fitted
```

Extended to the original time series yields the following forecasts can be deduced:

```{r, exe-3-6, echo = F}
# forecasts
fc.vec <- tail(round(fc.nz.dem.vec/fc.int.arr.vec,3),-1)
# periods
fc.per.vec <- c(0,tail(per.vec[ts3 > 0], -1), length(ts3)+1)
# number of periods per forecast value
fc.dper.vec <- diff(fc.per.vec)
# expand forecasts
fc.vec <- rep(fc.vec , times = fc.dper.vec)
# bind to data frame
res <- data.frame( "y" = c(ts3,NA) , "forecast" = fc.vec)
# display 
#datatable(res, options = list(pageLength =nrow(res) ))
kable(res)
plot(1:nrow(res), res$y, type="b", pch=16, ylab="demand")
lines(1:nrow(res), res$forecast, type="b", pch=17, col="darkgrey", lty=2)
```

Note that the forecasts based on Croston's method do not change until a new non-zero demand occurs.





